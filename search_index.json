{"index":{"version":"0.5.12","fields":[{"name":"title","boost":10},{"name":"keywords","boost":15},{"name":"body","boost":1}],"ref":"url","documentStore":{"store":{"./":["introduct","分析解读最新的自然语言处理方面的论文，供大家一起进行交流和学习。","将相关的知识进行整理后分享，方便后面的人学习","将自然语言处理方面的工具进行整理汇总","工具整理","收集整理相关成员上传的资料及相应的数据集，方便有需要的同学进行下载。","收集整理自然语言处理领域的会议及期刊，方便大家进行相关的查阅。","数据集","知识分享","自然语言处理会议及期刊","论文解读","该博客主要收集整理与自然语言处理相关工具，论文以及代码等资源信息，对目前自然语言处理最前沿的技术、论文及相关相关代码进行整理后进行分享，主要关注点包括自然语言处理基础方法，知识图谱构建，智能问答等几个方面的知识。通过不断地积累让大家在这条路上越走越远。"],"metting/summit metting.html":["aaai,全称是associ","ac(lth","acl","acl的全称是th","acl（tacl），此外还有一些期刊与自然语言处理相关。如tslp(（acm","acm","acm）主办，包括如下几个会议。","advanc","ai","ai,artifici","aistat","american","approach","artifici","asia","asian","associ","association)组织","a类","base","b类","ccf","chapter","cikm,该会议名称缩写和上一个相同，但是其全称为intern","cikmm,其全称是confer","cole","coling(intern","committe","comput","confer","conference，也是有关信息检索及数据挖掘。","conll","conll(confer","c类","data","data&corpu","emnlp","emnlp(confer","emnlp是有acl下面的比较著名的兴趣小组（speci","empir","evaluation,其由欧洲语言资源组织进行elra(european","evaluation,该会议由acl的特殊兴趣小组siglex进行组织，每年都会举办，国内也有很多研究机构及公司参与，如哈工大科大讯飞等,其最新的链接网址如下：http://alt.qcri.org/semeval2019/index.php?id=task","group","groups,sigs）之一的sigdata(speci","hearst正式宣布成立国际计算语言学学会亚太地区分会（aacl，th","http://coling2018.org","http://emnlp2018.org","http://naacl.org","http://www.conll.org/","https://blog.csdn.net/lyb3b3b/article/details/83548964","https://www.aclweb.org/port","https://www.cnblogs.com/niuxichuan/p/7602012.html","icml,全称是","ijcai,全称是intern","inform","intellig","intelligence，主要关注人工智能领域的最新研究进展，其中也有大量的人工智能相关的知识。","intelligence，也是关注人工智能领域的另外一个重要学术会议。","interest","intern","jair,journ","jmlr,","joint","journal","knowledg","languag","learn","learnin)","learning)举办的。其也是每年举办一次，由于naacl是acl在北美的分会，因此当acl在北美举办的时候，naacl就会停办一年。","linguist","linguistics)","linguistics)组织的。该会议每两年举办一次。","linguistics,其由1965年创办，是由老牌的nlp学术会议组织iccl(th","linguistics,翻译过来是计算机语言协会，自然语言处理与计算语言学领域（以下简称nlp/cl）最权威的国际专业学会，acl成立于1962年，是自然语言处理(nlp)领域影响力最大、最具活力的顶级国际学术组织，每年举办一次。这个学会主办了","linguistics,该会议是acl在北美的分会，也是有acl主办。其是有acl下面的兴趣小组signal(speci","linguistics和transact","linguistics）。此次成立acl亚太分会，将进一步促进亚太地区nlp相关技术和研究的发展。据悉，首届aacl会议预计在2020年举行，此后将每两年举行一次。","lrec","lrec全称是intern","machin","machinery,","management，其关注信息管理","method","mining,由名称可知，该会议关注搜索和数据挖掘。","naacl","naacl(th","naacl的全称是th","natur","nc,neurocompt","neural","nip","nlp/cl","nlp相关的其他国际会议","north","pacif","process","processing)","processing)),其他相关期刊及投稿链接如下：","processing)举办的。","processing,nlp）领域的一些著名会议及期刊，将按照ccf对会议的分级标准对相关会议进行整理，介绍每个会议的关注主题，召开周期、会议网站及相关的信息，方便后面查找最新的相关论文，从而对该领域进行比较深入的研究。每个会议及期刊都有相关的入口链接，方便进行查看。","processing.","processing）)以及talip((acm","research","resourc","retrieval,其主要关注信息检索。","search","semant","semev","semeval,其全称是intern","sigir,其全称是speci","speech","statist","system","transact","uai","uncertainti","web","wide","workshop","world","wsdm,该会议全称为web","人工智能领域与自然语言处理相关的会议","以下是根据ccf2015年的对自然语言处理领域的会议的分级标准来进行罗列和整理","会议名称","会议网站","全称","全称是confer","全称是intern","出版社","分类等级","参考文献","召开周期","国际会议","在国际上acl，coling，enmlp和naacl是默认的四大自然语言处理顶级学术会议，其中acl，emnlp和naacl都是由acl及相应的子组织举办的。","在自然语言处理中，一般来将，大家更关注学术会议，其主要原因是发表周期短，通过会议也可以进行深入的交流。但自然语言处理领域也有自己的学术期刊，其旗舰期刊有两个，分别是comput","在自然语言处理中，机器学习也是其主流的方法，在机器学习领域相关的学术会议包括icml,nips,uai及aistats,下面将简单介绍。","处理和人工智能是密切相关的，其是人工智能研究的重要内容，人工智能研究的两大国际顶会是aaai和ijcai","期刊","本文介绍自然语言处理（natur","机器学习领域中与自然语言处理相关的顶级会议","每两年一次","每年一次","自然语言","除了上述被ccf收录的会议外，在自然语言处理领域还有其他许多重要会议，分别是semeval,lrec等。","除了直接与自然语言处理相关外，还有其他许多与自然语言处理相关的学术会议，包括信息检索，数据挖掘及人工智能领域，这些都是属于自然语言处理的应用领域。其中信息检索和数据挖掘与自然语言处理是密切相关的，主要由美国计算机学会（associ","领域最权威的国际会议，即acl年会。1982年和1999年，acl分别成立了欧洲分会（eacl）和北美分会（naacl）两个区域性分会。近年来，亚太地区在自然语言处理方面的研究进步显著，2018年7月15日，第56届acl年会在澳大利亚墨尔本举行。开幕仪式上，acl主席marti"],"tools/readme.html":["tool"],"database/readme.html":["databas","下载地址：链接：https://pan.baidu.com/s/1nmh33yk80sznki8vhmeeea","分享者：刘露平","时间：2019年3月27日","概述：该ppt是做汇报时候的ppt，讲了知识图谱的基本知识及实体和关系抽取相关论文，有需要可以下载。","知识图谱概述ppt","该页面收集整理日常工作中相关的数据集和资料，大家可以通过将相关资料放到网盘或者其他github仓库中，然后这里放上相应的链接。","（永久有效）提取码：mdan"],"paper/readme.html":["2019","ariv","bert:","bidirect","deep","languag","paper","pre","train","transform","understand","该部分主要是分享目前自然语言及知识图谱处理方法的基础知识，目前包含如下三个方面：自然语言处理基础技术，知识图谱构建，智能问答,论文整理将按照年份和板块来进行整理。"],"paper/nlp/readme.html":["11项自然语言处理任务中都取得了目前最好的性能，具体包括将glue的基准值提升到了80.4%(7.6%的绝对提升)，在multnli中准确率有了86.7的提升（5.6%的绝对提升），在squad","2018年","2019年","abstract：","ariv","bert:","bidirect","deep","encod","keywords:","languag","nlp","pre","represent","train","transform","transformers。与近年来提出的语言模型不一样的地方在于，bert不再仅仅是只关注一个词前文或后文的信息，而是整个模型的所有层都去关注其整个上下文的语境信息。实验结果证明，使用预训练过的bert模型，仅仅在后面再包一层输出层，并对其进行微调训练，就可以将其应用到其他多种任务中，例如问答、语言推断等，并且在这些后端任务中并不需要根据特定的任务需要对模型结构进行修改。bert是一种概念上简单，但根据经验推断其具有强大的性能。bert在","understand","v1.1的问答任务中其f1值达到了93.2（1.5%）的绝对提升，比人类的表现都搞了2.0的提升。","本文作者推出了一套新的语言表达模型bert，全称为bidirect","目录","研究性工作","预训练，迁移学习"],"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":["11项自然语言处理任务中都取得了目前最好的性能，具体包括将glue的基准值提升到了80.4%(7.6%的绝对提升)，在multnli中准确率达到86.7的（5.6%的绝对提升），在squad","2018年","abstract：本文作者推出了一套新的语言表达模型bert，全称为bidirect","bert","bidirect","chang,","deep","encod","googl","gpt(gener","https://arxiv.org/abs/1810.04805","https://blog.csdn.net/jilrvrtrc/article/details/83829470","jacobdevlin,m","kenton","kristina","languag","lee,","level级别的任务中都取得了较好的效果。在很多有特定需要的任务中也取得了较好的效果。","levle和token","optimal)，而在针对一些token级别的任务中，如squad的问答问题中，则这种方法有可能是毁灭性的，因此在这些任务中，纳入两个方面的信息是至关重要的。","pre","represent","toutanova","train","transform","transform)引入了最小任务的参数，在下游任务中，其通过简单的微调的方式来调整模型的参数。在以前的工作中，所有的预训练方法都是通过使用同样的目标函数并通过双向语言模型来学习更好的通用语言表示。","transformers(基于双向翻译编码的表示模型)。bert通过提出了两个新的预训练目标来解决以前的提到的单向限制问题：基于“masked”的语言模型（mlm），这种方法在1953年就曾经被提出。这种语言模型通过随机将输入句子中的token进行隐藏，然后预训练的目标就是基于上下文来预测出被覆盖掉的单词。不同于传统的从左到右的预训练语言模型，mlm训练目标使得我们能够充分利用左边和右边信息来训练一个更深的双向翻译模型。除了利用masked语言模型外，我们还在模型中引入了预测下一个句子的训练目标来同时训练句子对级别的表示模型。","transformers。与近年来提出的语言模型不一样的地方在于，bert不再仅仅是只关注一个词前文或后文的信息，而是整个模型的所有层都去关注其整个上下文的语境信息。实验结果证明，使用预训练过的bert模型，仅仅在后面再包一层输出层，并对其进行微调训练，就可以将其应用到其他多种任务中，例如问答、语言推断等，并且在这些后端任务中并不需要根据特定的任务需要对模型结构进行修改。bert是一种概念上简单，但在实际中却有强大的性能的模型。bert在","tuning）的方法。在基于特征的方法中，elmo(2018)是一种基于特征任务的模型，其包含一个预训练模型以及一些其他的特征。在微调模型中，openai","understand","v1.1的问答任务中其f1值达到了93.2（1.5%）的绝对提升，比人类的表现都搞了2.0的提升。","wei","​","作者信息","作者单位","关键词","其他解读","内容","原文链接","在11项自然语言处理任务中都取得了sota的结果。表明双向语言模型在文本处理中的重要性。","在这篇文章中我们证明了双向预训练模型的重要性。不同于传统的双向预测模型，bert使用了一种基于masked的语言模型来训练一种更深的语言模型。此外区别于传统的浅层双向语言模型，bert是一种使用深层次的双向语言模型。","在这篇文章中，我们任务目前的技术严重限制了预训练在语言表达方面的能力，特别是针对微调的方法。最大的缺陷是目前的预训练模型都是双向的，其严格限制了模型在进行预训练时的选择能力。例如在openaigp中，作者使用了从左到右的模型，使得句子中每个token只能被以前的词所关注。这种方式对句子级别的任务是次优的(sub","在这篇论文中，我们提出了一种基于微调的方法bert:bidirect","实验及结果","总结","我们展示了预训练模块可以消除在很多任务中需要依赖严重特征工程的任务。bert","摘要","时间","是第一个基于微调方法的语言表示模型，并且在sentenc","模型介绍","源码链接","目前有两种预训练的方法被用于下游处理任务中：基于特征的和基于微调（fine","相关工作","简介","语言预训练模型已经被证明能有效提升自然语言处理任务的性能。这些任务包括句子级别的任务如语言推理及解析，这些任务其目的是从句子级别推断句子间相互关系。此外还包括一些序列级别的任务，如命名实体识别，文本理解挑战任务（squad），这些任务模型中需要在序列级别产生经过微调后的更好的结果。","这篇文章的贡献如下：","项目","预训练，迁移学习"],"paper/KnowledgeBase/readme.html":["knowledgebas"]},"length":8},"tokenStore":{"root":{"1":{"1":{"docs":{},"项":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"都":{"docs":{},"取":{"docs":{},"得":{"docs":{},"了":{"docs":{},"目":{"docs":{},"前":{"docs":{},"最":{"docs":{},"好":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"，":{"docs":{},"具":{"docs":{},"体":{"docs":{},"包":{"docs":{},"括":{"docs":{},"将":{"docs":{},"g":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"的":{"docs":{},"基":{"docs":{},"准":{"docs":{},"值":{"docs":{},"提":{"docs":{},"升":{"docs":{},"到":{"docs":{},"了":{"8":{"0":{"docs":{},".":{"4":{"docs":{},"%":{"docs":{},"(":{"7":{"docs":{},".":{"6":{"docs":{},"%":{"docs":{},"的":{"docs":{},"绝":{"docs":{},"对":{"docs":{},"提":{"docs":{},"升":{"docs":{},")":{"docs":{},"，":{"docs":{},"在":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"n":{"docs":{},"l":{"docs":{},"i":{"docs":{},"中":{"docs":{},"准":{"docs":{},"确":{"docs":{},"率":{"docs":{},"有":{"docs":{},"了":{"8":{"6":{"docs":{},".":{"7":{"docs":{},"的":{"docs":{},"提":{"docs":{},"升":{"docs":{},"（":{"5":{"docs":{},".":{"6":{"docs":{},"%":{"docs":{},"的":{"docs":{},"绝":{"docs":{},"对":{"docs":{},"提":{"docs":{},"升":{"docs":{},"）":{"docs":{},"，":{"docs":{},"在":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}},"docs":{}}},"docs":{}},"docs":{}}},"达":{"docs":{},"到":{"8":{"6":{"docs":{},".":{"7":{"docs":{},"的":{"docs":{},"（":{"5":{"docs":{},".":{"6":{"docs":{},"%":{"docs":{},"的":{"docs":{},"绝":{"docs":{},"对":{"docs":{},"提":{"docs":{},"升":{"docs":{},"）":{"docs":{},"，":{"docs":{},"在":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}},"docs":{}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}},"docs":{}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"2":{"0":{"1":{"8":{"docs":{},"年":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"9":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091}},"年":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":10}}}}}}}},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"关":{"docs":{},"注":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"最":{"docs":{},"新":{"docs":{},"研":{"docs":{},"究":{"docs":{},"进":{"docs":{},"展":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"也":{"docs":{},"有":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"也":{"docs":{},"是":{"docs":{},"关":{"docs":{},"注":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"另":{"docs":{},"外":{"docs":{},"一":{"docs":{},"个":{"docs":{},"重":{"docs":{},"要":{"docs":{},"学":{"docs":{},"术":{"docs":{},"会":{"docs":{},"议":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0182648401826484}}}}},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0182648401826484}}}}}}},"c":{"docs":{},"m":{"docs":{},"l":{"docs":{},",":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}},"j":{"docs":{},"c":{"docs":{},"a":{"docs":{},"i":{"docs":{},",":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}},"分":{"docs":{},"析":{"docs":{},"解":{"docs":{},"读":{"docs":{},"最":{"docs":{},"新":{"docs":{},"的":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"论":{"docs":{},"文":{"docs":{},"，":{"docs":{},"供":{"docs":{},"大":{"docs":{},"家":{"docs":{},"一":{"docs":{},"起":{"docs":{},"进":{"docs":{},"行":{"docs":{},"交":{"docs":{},"流":{"docs":{},"和":{"docs":{},"学":{"docs":{},"习":{"docs":{},"。":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"等":{"docs":{},"级":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"享":{"docs":{},"者":{"docs":{},"：":{"docs":{},"刘":{"docs":{},"露":{"docs":{},"平":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}}}}}}},"将":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"进":{"docs":{},"行":{"docs":{},"整":{"docs":{},"理":{"docs":{},"后":{"docs":{},"分":{"docs":{},"享":{"docs":{},"，":{"docs":{},"方":{"docs":{},"便":{"docs":{},"后":{"docs":{},"面":{"docs":{},"的":{"docs":{},"人":{"docs":{},"学":{"docs":{},"习":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"工":{"docs":{},"具":{"docs":{},"进":{"docs":{},"行":{"docs":{},"整":{"docs":{},"理":{"docs":{},"汇":{"docs":{},"总":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}},"工":{"docs":{},"具":{"docs":{},"整":{"docs":{},"理":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}},"收":{"docs":{},"集":{"docs":{},"整":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"成":{"docs":{},"员":{"docs":{},"上":{"docs":{},"传":{"docs":{},"的":{"docs":{},"资":{"docs":{},"料":{"docs":{},"及":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"，":{"docs":{},"方":{"docs":{},"便":{"docs":{},"有":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"同":{"docs":{},"学":{"docs":{},"进":{"docs":{},"行":{"docs":{},"下":{"docs":{},"载":{"docs":{},"。":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"会":{"docs":{},"议":{"docs":{},"及":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"，":{"docs":{},"方":{"docs":{},"便":{"docs":{},"大":{"docs":{},"家":{"docs":{},"进":{"docs":{},"行":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"查":{"docs":{},"阅":{"docs":{},"。":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}},"知":{"docs":{},"识":{"docs":{},"分":{"docs":{},"享":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}},"图":{"docs":{},"谱":{"docs":{},"概":{"docs":{},"述":{"docs":{},"p":{"docs":{},"p":{"docs":{},"t":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}}}}}}}}},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"处":{"docs":{},"理":{"docs":{},"会":{"docs":{},"议":{"docs":{},"及":{"docs":{},"期":{"docs":{},"刊":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}},"论":{"docs":{},"文":{"docs":{},"解":{"docs":{},"读":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}},"该":{"docs":{},"博":{"docs":{},"客":{"docs":{},"主":{"docs":{},"要":{"docs":{},"收":{"docs":{},"集":{"docs":{},"整":{"docs":{},"理":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"工":{"docs":{},"具":{"docs":{},"，":{"docs":{},"论":{"docs":{},"文":{"docs":{},"以":{"docs":{},"及":{"docs":{},"代":{"docs":{},"码":{"docs":{},"等":{"docs":{},"资":{"docs":{},"源":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"对":{"docs":{},"目":{"docs":{},"前":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"最":{"docs":{},"前":{"docs":{},"沿":{"docs":{},"的":{"docs":{},"技":{"docs":{},"术":{"docs":{},"、":{"docs":{},"论":{"docs":{},"文":{"docs":{},"及":{"docs":{},"相":{"docs":{},"关":{"docs":{},"相":{"docs":{},"关":{"docs":{},"代":{"docs":{},"码":{"docs":{},"进":{"docs":{},"行":{"docs":{},"整":{"docs":{},"理":{"docs":{},"后":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"享":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"关":{"docs":{},"注":{"docs":{},"点":{"docs":{},"包":{"docs":{},"括":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"基":{"docs":{},"础":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"构":{"docs":{},"建":{"docs":{},"，":{"docs":{},"智":{"docs":{},"能":{"docs":{},"问":{"docs":{},"答":{"docs":{},"等":{"docs":{},"几":{"docs":{},"个":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"。":{"docs":{},"通":{"docs":{},"过":{"docs":{},"不":{"docs":{},"断":{"docs":{},"地":{"docs":{},"积":{"docs":{},"累":{"docs":{},"让":{"docs":{},"大":{"docs":{},"家":{"docs":{},"在":{"docs":{},"这":{"docs":{},"条":{"docs":{},"路":{"docs":{},"上":{"docs":{},"越":{"docs":{},"走":{"docs":{},"越":{"docs":{},"远":{"docs":{},"。":{"docs":{"./":{"ref":"./","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"页":{"docs":{},"面":{"docs":{},"收":{"docs":{},"集":{"docs":{},"整":{"docs":{},"理":{"docs":{},"日":{"docs":{},"常":{"docs":{},"工":{"docs":{},"作":{"docs":{},"中":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"和":{"docs":{},"资":{"docs":{},"料":{"docs":{},"，":{"docs":{},"大":{"docs":{},"家":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"将":{"docs":{},"相":{"docs":{},"关":{"docs":{},"资":{"docs":{},"料":{"docs":{},"放":{"docs":{},"到":{"docs":{},"网":{"docs":{},"盘":{"docs":{},"或":{"docs":{},"者":{"docs":{},"其":{"docs":{},"他":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"仓":{"docs":{},"库":{"docs":{},"中":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"这":{"docs":{},"里":{"docs":{},"放":{"docs":{},"上":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"链":{"docs":{},"接":{"docs":{},"。":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"分":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"分":{"docs":{},"享":{"docs":{},"目":{"docs":{},"前":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"及":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"处":{"docs":{},"理":{"docs":{},"方":{"docs":{},"法":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"知":{"docs":{},"识":{"docs":{},"，":{"docs":{},"目":{"docs":{},"前":{"docs":{},"包":{"docs":{},"含":{"docs":{},"如":{"docs":{},"下":{"docs":{},"三":{"docs":{},"个":{"docs":{},"方":{"docs":{},"面":{"docs":{},"：":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"基":{"docs":{},"础":{"docs":{},"技":{"docs":{},"术":{"docs":{},"，":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"构":{"docs":{},"建":{"docs":{},"，":{"docs":{},"智":{"docs":{},"能":{"docs":{},"问":{"docs":{},"答":{"docs":{},",":{"docs":{},"论":{"docs":{},"文":{"docs":{},"整":{"docs":{},"理":{"docs":{},"将":{"docs":{},"按":{"docs":{},"照":{"docs":{},"年":{"docs":{},"份":{"docs":{},"和":{"docs":{},"板":{"docs":{},"块":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"整":{"docs":{},"理":{"docs":{},"。":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"a":{"docs":{},"a":{"docs":{},"i":{"docs":{},",":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}},"c":{"docs":{},"(":{"docs":{},"l":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}},"的":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}},"（":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"）":{"docs":{},"，":{"docs":{},"此":{"docs":{},"外":{"docs":{},"还":{"docs":{},"有":{"docs":{},"一":{"docs":{},"些":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"。":{"docs":{},"如":{"docs":{},"t":{"docs":{},"s":{"docs":{},"l":{"docs":{},"p":{"docs":{},"(":{"docs":{},"（":{"docs":{},"a":{"docs":{},"c":{"docs":{},"m":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"）":{"docs":{},"主":{"docs":{},"办":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"如":{"docs":{},"下":{"docs":{},"几":{"docs":{},"个":{"docs":{},"会":{"docs":{},"议":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}},"d":{"docs":{},"v":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},",":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0182648401826484}}}}}}}},"i":{"docs":{},"v":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}},"s":{"docs":{},"i":{"docs":{},"a":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"s":{"docs":{},"o":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0228310502283105}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{},"组":{"docs":{},"织":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}},"类":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}},"b":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"：":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}},"本":{"docs":{},"文":{"docs":{},"作":{"docs":{},"者":{"docs":{},"推":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"套":{"docs":{},"新":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"表":{"docs":{},"达":{"docs":{},"模":{"docs":{},"型":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"，":{"docs":{},"全":{"docs":{},"称":{"docs":{},"为":{"docs":{},"b":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"类":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2794117647058822}},":":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}}},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2647058823529411}}}}}}}}}},"c":{"docs":{},"c":{"docs":{},"f":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}}}},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}}}}}},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}},"i":{"docs":{},"k":{"docs":{},"m":{"docs":{},",":{"docs":{},"该":{"docs":{},"会":{"docs":{},"议":{"docs":{},"名":{"docs":{},"称":{"docs":{},"缩":{"docs":{},"写":{"docs":{},"和":{"docs":{},"上":{"docs":{},"一":{"docs":{},"个":{"docs":{},"相":{"docs":{},"同":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"其":{"docs":{},"全":{"docs":{},"称":{"docs":{},"为":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},",":{"docs":{},"其":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}},"o":{"docs":{},"l":{"docs":{},"e":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}},"m":{"docs":{},"m":{"docs":{},"i":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.045662100456621}}}}}},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":5.036529680365296}},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"也":{"docs":{},"是":{"docs":{},"有":{"docs":{},"关":{"docs":{},"信":{"docs":{},"息":{"docs":{},"检":{"docs":{},"索":{"docs":{},"及":{"docs":{},"数":{"docs":{},"据":{"docs":{},"挖":{"docs":{},"掘":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"(":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}},"类":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"&":{"docs":{},"c":{"docs":{},"o":{"docs":{},"r":{"docs":{},"p":{"docs":{},"u":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":10}}}}}}}},"e":{"docs":{},"e":{"docs":{},"p":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2647058823529411}}}}}},"e":{"docs":{},"m":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}},"(":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}},"是":{"docs":{},"有":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"下":{"docs":{},"面":{"docs":{},"的":{"docs":{},"比":{"docs":{},"较":{"docs":{},"著":{"docs":{},"名":{"docs":{},"的":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"小":{"docs":{},"组":{"docs":{},"（":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"i":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{},"其":{"docs":{},"由":{"docs":{},"欧":{"docs":{},"洲":{"docs":{},"语":{"docs":{},"言":{"docs":{},"资":{"docs":{},"源":{"docs":{},"组":{"docs":{},"织":{"docs":{},"进":{"docs":{},"行":{"docs":{},"e":{"docs":{},"l":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"e":{"docs":{},"u":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"a":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}},"该":{"docs":{},"会":{"docs":{},"议":{"docs":{},"由":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"的":{"docs":{},"特":{"docs":{},"殊":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"小":{"docs":{},"组":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},"x":{"docs":{},"进":{"docs":{},"行":{"docs":{},"组":{"docs":{},"织":{"docs":{},"，":{"docs":{},"每":{"docs":{},"年":{"docs":{},"都":{"docs":{},"会":{"docs":{},"举":{"docs":{},"办":{"docs":{},"，":{"docs":{},"国":{"docs":{},"内":{"docs":{},"也":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"研":{"docs":{},"究":{"docs":{},"机":{"docs":{},"构":{"docs":{},"及":{"docs":{},"公":{"docs":{},"司":{"docs":{},"参":{"docs":{},"与":{"docs":{},"，":{"docs":{},"如":{"docs":{},"哈":{"docs":{},"工":{"docs":{},"大":{"docs":{},"科":{"docs":{},"大":{"docs":{},"讯":{"docs":{},"飞":{"docs":{},"等":{"docs":{},",":{"docs":{},"其":{"docs":{},"最":{"docs":{},"新":{"docs":{},"的":{"docs":{},"链":{"docs":{},"接":{"docs":{},"网":{"docs":{},"址":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"a":{"docs":{},"l":{"docs":{},"t":{"docs":{},".":{"docs":{},"q":{"docs":{},"c":{"docs":{},"r":{"docs":{},"i":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"s":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"2":{"0":{"1":{"9":{"docs":{},"/":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},".":{"docs":{},"p":{"docs":{},"h":{"docs":{},"p":{"docs":{},"?":{"docs":{},"i":{"docs":{},"d":{"docs":{},"=":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.029411764705882353}}}}}}},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}},"s":{"docs":{},",":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"s":{"docs":{},"）":{"docs":{},"之":{"docs":{},"一":{"docs":{},"的":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"(":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"p":{"docs":{},"t":{"docs":{},"(":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{},"正":{"docs":{},"式":{"docs":{},"宣":{"docs":{},"布":{"docs":{},"成":{"docs":{},"立":{"docs":{},"国":{"docs":{},"际":{"docs":{},"计":{"docs":{},"算":{"docs":{},"语":{"docs":{},"言":{"docs":{},"学":{"docs":{},"学":{"docs":{},"会":{"docs":{},"亚":{"docs":{},"太":{"docs":{},"地":{"docs":{},"区":{"docs":{},"分":{"docs":{},"会":{"docs":{},"（":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"，":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"2":{"0":{"1":{"8":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}},"e":{"docs":{},"m":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"2":{"0":{"1":{"8":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}},"w":{"docs":{},"w":{"docs":{},"w":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"l":{"docs":{},"l":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},".":{"docs":{},"c":{"docs":{},"s":{"docs":{},"d":{"docs":{},"n":{"docs":{},".":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"/":{"docs":{},"l":{"docs":{},"y":{"docs":{},"b":{"3":{"docs":{},"b":{"3":{"docs":{},"b":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"l":{"docs":{},"e":{"docs":{},"/":{"docs":{},"d":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"s":{"docs":{},"/":{"8":{"3":{"5":{"4":{"8":{"9":{"6":{"4":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}},"j":{"docs":{},"i":{"docs":{},"l":{"docs":{},"r":{"docs":{},"v":{"docs":{},"r":{"docs":{},"t":{"docs":{},"r":{"docs":{},"c":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"l":{"docs":{},"e":{"docs":{},"/":{"docs":{},"d":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"s":{"docs":{},"/":{"8":{"3":{"8":{"2":{"9":{"4":{"7":{"0":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"w":{"docs":{},"w":{"docs":{},".":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"w":{"docs":{},"e":{"docs":{},"b":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}},"c":{"docs":{},"n":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"n":{"docs":{},"i":{"docs":{},"u":{"docs":{},"x":{"docs":{},"i":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"/":{"docs":{},"p":{"docs":{},"/":{"7":{"6":{"0":{"2":{"0":{"1":{"2":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"a":{"docs":{},"b":{"docs":{},"s":{"docs":{},"/":{"1":{"8":{"1":{"0":{"docs":{},".":{"0":{"4":{"8":{"0":{"5":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"j":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{},",":{"docs":{},"j":{"docs":{},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"b":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},",":{"docs":{},"m":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}},"m":{"docs":{},"l":{"docs":{},"r":{"docs":{},",":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"u":{"docs":{},"r":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":5.004566210045662}}}}}}}}},"k":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"g":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"e":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{"paper/KnowledgeBase/readme.html":{"ref":"paper/KnowledgeBase/readme.html","tf":10}}}}}}}}}}}}},"e":{"docs":{},"y":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"s":{"docs":{},":":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}}}}}},"n":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}},"r":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"u":{"docs":{},"a":{"docs":{},"g":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.045662100456621},"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2647058823529411}}}}}}}},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}},"i":{"docs":{},"n":{"docs":{},")":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}},"g":{"docs":{},")":{"docs":{},"举":{"docs":{},"办":{"docs":{},"的":{"docs":{},"。":{"docs":{},"其":{"docs":{},"也":{"docs":{},"是":{"docs":{},"每":{"docs":{},"年":{"docs":{},"举":{"docs":{},"办":{"docs":{},"一":{"docs":{},"次":{"docs":{},"，":{"docs":{},"由":{"docs":{},"于":{"docs":{},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"是":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"在":{"docs":{},"北":{"docs":{},"美":{"docs":{},"的":{"docs":{},"分":{"docs":{},"会":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"当":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"在":{"docs":{},"北":{"docs":{},"美":{"docs":{},"举":{"docs":{},"办":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"就":{"docs":{},"会":{"docs":{},"停":{"docs":{},"办":{"docs":{},"一":{"docs":{},"年":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},",":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"都":{"docs":{},"取":{"docs":{},"得":{"docs":{},"了":{"docs":{},"较":{"docs":{},"好":{"docs":{},"的":{"docs":{},"效":{"docs":{},"果":{"docs":{},"。":{"docs":{},"在":{"docs":{},"很":{"docs":{},"多":{"docs":{},"有":{"docs":{},"特":{"docs":{},"定":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"也":{"docs":{},"取":{"docs":{},"得":{"docs":{},"了":{"docs":{},"较":{"docs":{},"好":{"docs":{},"的":{"docs":{},"效":{"docs":{},"果":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"和":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"u":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"i":{"docs":{},"c":{"docs":{},"s":{"docs":{},")":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}},"组":{"docs":{},"织":{"docs":{},"的":{"docs":{},"。":{"docs":{},"该":{"docs":{},"会":{"docs":{},"议":{"docs":{},"每":{"docs":{},"两":{"docs":{},"年":{"docs":{},"举":{"docs":{},"办":{"docs":{},"一":{"docs":{},"次":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}},",":{"docs":{},"其":{"docs":{},"由":{"1":{"9":{"6":{"5":{"docs":{},"年":{"docs":{},"创":{"docs":{},"办":{"docs":{},"，":{"docs":{},"是":{"docs":{},"由":{"docs":{},"老":{"docs":{},"牌":{"docs":{},"的":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"学":{"docs":{},"术":{"docs":{},"会":{"docs":{},"议":{"docs":{},"组":{"docs":{},"织":{"docs":{},"i":{"docs":{},"c":{"docs":{},"c":{"docs":{},"l":{"docs":{},"(":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"翻":{"docs":{},"译":{"docs":{},"过":{"docs":{},"来":{"docs":{},"是":{"docs":{},"计":{"docs":{},"算":{"docs":{},"机":{"docs":{},"语":{"docs":{},"言":{"docs":{},"协":{"docs":{},"会":{"docs":{},"，":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"与":{"docs":{},"计":{"docs":{},"算":{"docs":{},"语":{"docs":{},"言":{"docs":{},"学":{"docs":{},"领":{"docs":{},"域":{"docs":{},"（":{"docs":{},"以":{"docs":{},"下":{"docs":{},"简":{"docs":{},"称":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"/":{"docs":{},"c":{"docs":{},"l":{"docs":{},"）":{"docs":{},"最":{"docs":{},"权":{"docs":{},"威":{"docs":{},"的":{"docs":{},"国":{"docs":{},"际":{"docs":{},"专":{"docs":{},"业":{"docs":{},"学":{"docs":{},"会":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"成":{"docs":{},"立":{"docs":{},"于":{"1":{"9":{"6":{"2":{"docs":{},"年":{"docs":{},"，":{"docs":{},"是":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"(":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},")":{"docs":{},"领":{"docs":{},"域":{"docs":{},"影":{"docs":{},"响":{"docs":{},"力":{"docs":{},"最":{"docs":{},"大":{"docs":{},"、":{"docs":{},"最":{"docs":{},"具":{"docs":{},"活":{"docs":{},"力":{"docs":{},"的":{"docs":{},"顶":{"docs":{},"级":{"docs":{},"国":{"docs":{},"际":{"docs":{},"学":{"docs":{},"术":{"docs":{},"组":{"docs":{},"织":{"docs":{},"，":{"docs":{},"每":{"docs":{},"年":{"docs":{},"举":{"docs":{},"办":{"docs":{},"一":{"docs":{},"次":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"学":{"docs":{},"会":{"docs":{},"主":{"docs":{},"办":{"docs":{},"了":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"该":{"docs":{},"会":{"docs":{},"议":{"docs":{},"是":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"在":{"docs":{},"北":{"docs":{},"美":{"docs":{},"的":{"docs":{},"分":{"docs":{},"会":{"docs":{},"，":{"docs":{},"也":{"docs":{},"是":{"docs":{},"有":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"主":{"docs":{},"办":{"docs":{},"。":{"docs":{},"其":{"docs":{},"是":{"docs":{},"有":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"下":{"docs":{},"面":{"docs":{},"的":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"小":{"docs":{},"组":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"(":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}},"）":{"docs":{},"。":{"docs":{},"此":{"docs":{},"次":{"docs":{},"成":{"docs":{},"立":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"亚":{"docs":{},"太":{"docs":{},"分":{"docs":{},"会":{"docs":{},"，":{"docs":{},"将":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"促":{"docs":{},"进":{"docs":{},"亚":{"docs":{},"太":{"docs":{},"地":{"docs":{},"区":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"相":{"docs":{},"关":{"docs":{},"技":{"docs":{},"术":{"docs":{},"和":{"docs":{},"研":{"docs":{},"究":{"docs":{},"的":{"docs":{},"发":{"docs":{},"展":{"docs":{},"。":{"docs":{},"据":{"docs":{},"悉":{"docs":{},"，":{"docs":{},"首":{"docs":{},"届":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"会":{"docs":{},"议":{"docs":{},"预":{"docs":{},"计":{"docs":{},"在":{"2":{"0":{"2":{"0":{"docs":{},"年":{"docs":{},"举":{"docs":{},"行":{"docs":{},"，":{"docs":{},"此":{"docs":{},"后":{"docs":{},"将":{"docs":{},"每":{"docs":{},"两":{"docs":{},"年":{"docs":{},"举":{"docs":{},"行":{"docs":{},"一":{"docs":{},"次":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},",":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"，":{"docs":{},"其":{"docs":{},"关":{"docs":{},"注":{"docs":{},"信":{"docs":{},"息":{"docs":{},"管":{"docs":{},"理":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}}}},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{},"由":{"docs":{},"名":{"docs":{},"称":{"docs":{},"可":{"docs":{},"知":{"docs":{},"，":{"docs":{},"该":{"docs":{},"会":{"docs":{},"议":{"docs":{},"关":{"docs":{},"注":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"挖":{"docs":{},"掘":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}},"(":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"的":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0228310502283105}}}}}},"c":{"docs":{},",":{"docs":{},"n":{"docs":{},"e":{"docs":{},"u":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}},"e":{"docs":{},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"i":{"docs":{},"p":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}},"l":{"docs":{},"p":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":10}},"/":{"docs":{},"c":{"docs":{},"l":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"其":{"docs":{},"他":{"docs":{},"国":{"docs":{},"际":{"docs":{},"会":{"docs":{},"议":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}}}},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"i":{"docs":{},"f":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":10}}}}}},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},")":{"docs":{},",":{"docs":{},"其":{"docs":{},"他":{"docs":{},"相":{"docs":{},"关":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"及":{"docs":{},"投":{"docs":{},"稿":{"docs":{},"链":{"docs":{},"接":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}},"举":{"docs":{},"办":{"docs":{},"的":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},",":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"）":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"一":{"docs":{},"些":{"docs":{},"著":{"docs":{},"名":{"docs":{},"会":{"docs":{},"议":{"docs":{},"及":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"，":{"docs":{},"将":{"docs":{},"按":{"docs":{},"照":{"docs":{},"c":{"docs":{},"c":{"docs":{},"f":{"docs":{},"对":{"docs":{},"会":{"docs":{},"议":{"docs":{},"的":{"docs":{},"分":{"docs":{},"级":{"docs":{},"标":{"docs":{},"准":{"docs":{},"对":{"docs":{},"相":{"docs":{},"关":{"docs":{},"会":{"docs":{},"议":{"docs":{},"进":{"docs":{},"行":{"docs":{},"整":{"docs":{},"理":{"docs":{},"，":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"每":{"docs":{},"个":{"docs":{},"会":{"docs":{},"议":{"docs":{},"的":{"docs":{},"关":{"docs":{},"注":{"docs":{},"主":{"docs":{},"题":{"docs":{},"，":{"docs":{},"召":{"docs":{},"开":{"docs":{},"周":{"docs":{},"期":{"docs":{},"、":{"docs":{},"会":{"docs":{},"议":{"docs":{},"网":{"docs":{},"站":{"docs":{},"及":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"方":{"docs":{},"便":{"docs":{},"后":{"docs":{},"面":{"docs":{},"查":{"docs":{},"找":{"docs":{},"最":{"docs":{},"新":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"论":{"docs":{},"文":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"对":{"docs":{},"该":{"docs":{},"领":{"docs":{},"域":{"docs":{},"进":{"docs":{},"行":{"docs":{},"比":{"docs":{},"较":{"docs":{},"深":{"docs":{},"入":{"docs":{},"的":{"docs":{},"研":{"docs":{},"究":{"docs":{},"。":{"docs":{},"每":{"docs":{},"个":{"docs":{},"会":{"docs":{},"议":{"docs":{},"及":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"都":{"docs":{},"有":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"入":{"docs":{},"口":{"docs":{},"链":{"docs":{},"接":{"docs":{},"，":{"docs":{},"方":{"docs":{},"便":{"docs":{},"进":{"docs":{},"行":{"docs":{},"查":{"docs":{},"看":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}},"）":{"docs":{},")":{"docs":{},"以":{"docs":{},"及":{"docs":{},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"p":{"docs":{},"(":{"docs":{},"(":{"docs":{},"a":{"docs":{},"c":{"docs":{},"m":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2794117647058822}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}}}},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}}}},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},",":{"docs":{},"其":{"docs":{},"主":{"docs":{},"要":{"docs":{},"关":{"docs":{},"注":{"docs":{},"信":{"docs":{},"息":{"docs":{},"检":{"docs":{},"索":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.029411764705882353}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"e":{"docs":{},"v":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}},"a":{"docs":{},"l":{"docs":{},",":{"docs":{},"其":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"g":{"docs":{},"i":{"docs":{},"r":{"docs":{},",":{"docs":{},"其":{"docs":{},"全":{"docs":{},"称":{"docs":{},"是":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}},"p":{"docs":{},"e":{"docs":{},"e":{"docs":{},"c":{"docs":{},"h":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}},"y":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0091324200913242}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2647058823529411}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"。":{"docs":{},"与":{"docs":{},"近":{"docs":{},"年":{"docs":{},"来":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{},"在":{"docs":{},"于":{"docs":{},"，":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"不":{"docs":{},"再":{"docs":{},"仅":{"docs":{},"仅":{"docs":{},"是":{"docs":{},"只":{"docs":{},"关":{"docs":{},"注":{"docs":{},"一":{"docs":{},"个":{"docs":{},"词":{"docs":{},"前":{"docs":{},"文":{"docs":{},"或":{"docs":{},"后":{"docs":{},"文":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"整":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"层":{"docs":{},"都":{"docs":{},"去":{"docs":{},"关":{"docs":{},"注":{"docs":{},"其":{"docs":{},"整":{"docs":{},"个":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"的":{"docs":{},"语":{"docs":{},"境":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{},"实":{"docs":{},"验":{"docs":{},"结":{"docs":{},"果":{"docs":{},"证":{"docs":{},"明":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"的":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"仅":{"docs":{},"仅":{"docs":{},"在":{"docs":{},"后":{"docs":{},"面":{"docs":{},"再":{"docs":{},"包":{"docs":{},"一":{"docs":{},"层":{"docs":{},"输":{"docs":{},"出":{"docs":{},"层":{"docs":{},"，":{"docs":{},"并":{"docs":{},"对":{"docs":{},"其":{"docs":{},"进":{"docs":{},"行":{"docs":{},"微":{"docs":{},"调":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{},"其":{"docs":{},"应":{"docs":{},"用":{"docs":{},"到":{"docs":{},"其":{"docs":{},"他":{"docs":{},"多":{"docs":{},"种":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"问":{"docs":{},"答":{"docs":{},"、":{"docs":{},"语":{"docs":{},"言":{"docs":{},"推":{"docs":{},"断":{"docs":{},"等":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"在":{"docs":{},"这":{"docs":{},"些":{"docs":{},"后":{"docs":{},"端":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"并":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"根":{"docs":{},"据":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"需":{"docs":{},"要":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"结":{"docs":{},"构":{"docs":{},"进":{"docs":{},"行":{"docs":{},"修":{"docs":{},"改":{"docs":{},"。":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"概":{"docs":{},"念":{"docs":{},"上":{"docs":{},"简":{"docs":{},"单":{"docs":{},"，":{"docs":{},"但":{"docs":{},"根":{"docs":{},"据":{"docs":{},"经":{"docs":{},"验":{"docs":{},"推":{"docs":{},"断":{"docs":{},"其":{"docs":{},"具":{"docs":{},"有":{"docs":{},"强":{"docs":{},"大":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"在":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"实":{"docs":{},"际":{"docs":{},"中":{"docs":{},"却":{"docs":{},"有":{"docs":{},"强":{"docs":{},"大":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"在":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"基":{"docs":{},"于":{"docs":{},"双":{"docs":{},"向":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"编":{"docs":{},"码":{"docs":{},"的":{"docs":{},"表":{"docs":{},"示":{"docs":{},"模":{"docs":{},"型":{"docs":{},")":{"docs":{},"。":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"通":{"docs":{},"过":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"两":{"docs":{},"个":{"docs":{},"新":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"目":{"docs":{},"标":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"以":{"docs":{},"前":{"docs":{},"的":{"docs":{},"提":{"docs":{},"到":{"docs":{},"的":{"docs":{},"单":{"docs":{},"向":{"docs":{},"限":{"docs":{},"制":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"基":{"docs":{},"于":{"docs":{},"“":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"”":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"（":{"docs":{},"m":{"docs":{},"l":{"docs":{},"m":{"docs":{},"）":{"docs":{},"，":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"在":{"1":{"9":{"5":{"3":{"docs":{},"年":{"docs":{},"就":{"docs":{},"曾":{"docs":{},"经":{"docs":{},"被":{"docs":{},"提":{"docs":{},"出":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"通":{"docs":{},"过":{"docs":{},"随":{"docs":{},"机":{"docs":{},"将":{"docs":{},"输":{"docs":{},"入":{"docs":{},"句":{"docs":{},"子":{"docs":{},"中":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"进":{"docs":{},"行":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"就":{"docs":{},"是":{"docs":{},"基":{"docs":{},"于":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"来":{"docs":{},"预":{"docs":{},"测":{"docs":{},"出":{"docs":{},"被":{"docs":{},"覆":{"docs":{},"盖":{"docs":{},"掉":{"docs":{},"的":{"docs":{},"单":{"docs":{},"词":{"docs":{},"。":{"docs":{},"不":{"docs":{},"同":{"docs":{},"于":{"docs":{},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"从":{"docs":{},"左":{"docs":{},"到":{"docs":{},"右":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"m":{"docs":{},"l":{"docs":{},"m":{"docs":{},"训":{"docs":{},"练":{"docs":{},"目":{"docs":{},"标":{"docs":{},"使":{"docs":{},"得":{"docs":{},"我":{"docs":{},"们":{"docs":{},"能":{"docs":{},"够":{"docs":{},"充":{"docs":{},"分":{"docs":{},"利":{"docs":{},"用":{"docs":{},"左":{"docs":{},"边":{"docs":{},"和":{"docs":{},"右":{"docs":{},"边":{"docs":{},"信":{"docs":{},"息":{"docs":{},"来":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"个":{"docs":{},"更":{"docs":{},"深":{"docs":{},"的":{"docs":{},"双":{"docs":{},"向":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"除":{"docs":{},"了":{"docs":{},"利":{"docs":{},"用":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"外":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"还":{"docs":{},"在":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"引":{"docs":{},"入":{"docs":{},"了":{"docs":{},"预":{"docs":{},"测":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"句":{"docs":{},"子":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"目":{"docs":{},"标":{"docs":{},"来":{"docs":{},"同":{"docs":{},"时":{"docs":{},"训":{"docs":{},"练":{"docs":{},"句":{"docs":{},"子":{"docs":{},"对":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"表":{"docs":{},"示":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{},"引":{"docs":{},"入":{"docs":{},"了":{"docs":{},"最":{"docs":{},"小":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"在":{"docs":{},"下":{"docs":{},"游":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"，":{"docs":{},"其":{"docs":{},"通":{"docs":{},"过":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"微":{"docs":{},"调":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"来":{"docs":{},"调":{"docs":{},"整":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{},"在":{"docs":{},"以":{"docs":{},"前":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"中":{"docs":{},"，":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"方":{"docs":{},"法":{"docs":{},"都":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"使":{"docs":{},"用":{"docs":{},"同":{"docs":{},"样":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"函":{"docs":{},"数":{"docs":{},"并":{"docs":{},"通":{"docs":{},"过":{"docs":{},"双":{"docs":{},"向":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"学":{"docs":{},"习":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"通":{"docs":{},"用":{"docs":{},"语":{"docs":{},"言":{"docs":{},"表":{"docs":{},"示":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2794117647058822}}}}}},"o":{"docs":{},"o":{"docs":{},"l":{"docs":{"tools/readme.html":{"ref":"tools/readme.html","tf":10}}}},"u":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"o":{"docs":{},"v":{"docs":{},"a":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"）":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{},"在":{"docs":{},"基":{"docs":{},"于":{"docs":{},"特":{"docs":{},"征":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"中":{"docs":{},"，":{"docs":{},"e":{"docs":{},"l":{"docs":{},"m":{"docs":{},"o":{"docs":{},"(":{"2":{"0":{"1":{"8":{"docs":{},")":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"基":{"docs":{},"于":{"docs":{},"特":{"docs":{},"征":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"其":{"docs":{},"包":{"docs":{},"含":{"docs":{},"一":{"docs":{},"个":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"以":{"docs":{},"及":{"docs":{},"一":{"docs":{},"些":{"docs":{},"其":{"docs":{},"他":{"docs":{},"的":{"docs":{},"特":{"docs":{},"征":{"docs":{},"。":{"docs":{},"在":{"docs":{},"微":{"docs":{},"调":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"，":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"a":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"paper/readme.html":{"ref":"paper/readme.html","tf":0.09090909090909091},"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":1.2647058823529411}}}}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"b":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}},"i":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"s":{"docs":{},"h":{"docs":{},"o":{"docs":{},"p":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}},"l":{"docs":{},"d":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"s":{"docs":{},"d":{"docs":{},"m":{"docs":{},",":{"docs":{},"该":{"docs":{},"会":{"docs":{},"议":{"docs":{},"全":{"docs":{},"称":{"docs":{},"为":{"docs":{},"w":{"docs":{},"e":{"docs":{},"b":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"领":{"docs":{},"域":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"会":{"docs":{},"议":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}},"以":{"docs":{},"下":{"docs":{},"是":{"docs":{},"根":{"docs":{},"据":{"docs":{},"c":{"docs":{},"c":{"docs":{},"f":{"2":{"0":{"1":{"5":{"docs":{},"年":{"docs":{},"的":{"docs":{},"对":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"会":{"docs":{},"议":{"docs":{},"的":{"docs":{},"分":{"docs":{},"级":{"docs":{},"标":{"docs":{},"准":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"罗":{"docs":{},"列":{"docs":{},"和":{"docs":{},"整":{"docs":{},"理":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}},"会":{"docs":{},"议":{"docs":{},"名":{"docs":{},"称":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}},"网":{"docs":{},"站":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"全":{"docs":{},"称":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0136986301369863}},"是":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}},"出":{"docs":{},"版":{"docs":{},"社":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}},"参":{"docs":{},"考":{"docs":{},"文":{"docs":{},"献":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"召":{"docs":{},"开":{"docs":{},"周":{"docs":{},"期":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"国":{"docs":{},"际":{"docs":{},"会":{"docs":{},"议":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"在":{"1":{"1":{"docs":{},"项":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"都":{"docs":{},"取":{"docs":{},"得":{"docs":{},"了":{"docs":{},"s":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{},"表":{"docs":{},"明":{"docs":{},"双":{"docs":{},"向":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"文":{"docs":{},"本":{"docs":{},"处":{"docs":{},"理":{"docs":{},"中":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{},"性":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{},"国":{"docs":{},"际":{"docs":{},"上":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"，":{"docs":{},"c":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"，":{"docs":{},"e":{"docs":{},"n":{"docs":{},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"和":{"docs":{},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"是":{"docs":{},"默":{"docs":{},"认":{"docs":{},"的":{"docs":{},"四":{"docs":{},"大":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"顶":{"docs":{},"级":{"docs":{},"学":{"docs":{},"术":{"docs":{},"会":{"docs":{},"议":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"，":{"docs":{},"e":{"docs":{},"m":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"和":{"docs":{},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"都":{"docs":{},"是":{"docs":{},"由":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"及":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"子":{"docs":{},"组":{"docs":{},"织":{"docs":{},"举":{"docs":{},"办":{"docs":{},"的":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"中":{"docs":{},"，":{"docs":{},"一":{"docs":{},"般":{"docs":{},"来":{"docs":{},"将":{"docs":{},"，":{"docs":{},"大":{"docs":{},"家":{"docs":{},"更":{"docs":{},"关":{"docs":{},"注":{"docs":{},"学":{"docs":{},"术":{"docs":{},"会":{"docs":{},"议":{"docs":{},"，":{"docs":{},"其":{"docs":{},"主":{"docs":{},"要":{"docs":{},"原":{"docs":{},"因":{"docs":{},"是":{"docs":{},"发":{"docs":{},"表":{"docs":{},"周":{"docs":{},"期":{"docs":{},"短":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"会":{"docs":{},"议":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"进":{"docs":{},"行":{"docs":{},"深":{"docs":{},"入":{"docs":{},"的":{"docs":{},"交":{"docs":{},"流":{"docs":{},"。":{"docs":{},"但":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"领":{"docs":{},"域":{"docs":{},"也":{"docs":{},"有":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"学":{"docs":{},"术":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"，":{"docs":{},"其":{"docs":{},"旗":{"docs":{},"舰":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"有":{"docs":{},"两":{"docs":{},"个":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"是":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"也":{"docs":{},"是":{"docs":{},"其":{"docs":{},"主":{"docs":{},"流":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"在":{"docs":{},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"领":{"docs":{},"域":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"学":{"docs":{},"术":{"docs":{},"会":{"docs":{},"议":{"docs":{},"包":{"docs":{},"括":{"docs":{},"i":{"docs":{},"c":{"docs":{},"m":{"docs":{},"l":{"docs":{},",":{"docs":{},"n":{"docs":{},"i":{"docs":{},"p":{"docs":{},"s":{"docs":{},",":{"docs":{},"u":{"docs":{},"a":{"docs":{},"i":{"docs":{},"及":{"docs":{},"a":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{},"下":{"docs":{},"面":{"docs":{},"将":{"docs":{},"简":{"docs":{},"单":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"篇":{"docs":{},"文":{"docs":{},"章":{"docs":{},"中":{"docs":{},"我":{"docs":{},"们":{"docs":{},"证":{"docs":{},"明":{"docs":{},"了":{"docs":{},"双":{"docs":{},"向":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{},"性":{"docs":{},"。":{"docs":{},"不":{"docs":{},"同":{"docs":{},"于":{"docs":{},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"双":{"docs":{},"向":{"docs":{},"预":{"docs":{},"测":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"一":{"docs":{},"种":{"docs":{},"基":{"docs":{},"于":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"来":{"docs":{},"训":{"docs":{},"练":{"docs":{},"一":{"docs":{},"种":{"docs":{},"更":{"docs":{},"深":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"此":{"docs":{},"外":{"docs":{},"区":{"docs":{},"别":{"docs":{},"于":{"docs":{},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"浅":{"docs":{},"层":{"docs":{},"双":{"docs":{},"向":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"使":{"docs":{},"用":{"docs":{},"深":{"docs":{},"层":{"docs":{},"次":{"docs":{},"的":{"docs":{},"双":{"docs":{},"向":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"任":{"docs":{},"务":{"docs":{},"目":{"docs":{},"前":{"docs":{},"的":{"docs":{},"技":{"docs":{},"术":{"docs":{},"严":{"docs":{},"重":{"docs":{},"限":{"docs":{},"制":{"docs":{},"了":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"在":{"docs":{},"语":{"docs":{},"言":{"docs":{},"表":{"docs":{},"达":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"能":{"docs":{},"力":{"docs":{},"，":{"docs":{},"特":{"docs":{},"别":{"docs":{},"是":{"docs":{},"针":{"docs":{},"对":{"docs":{},"微":{"docs":{},"调":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{},"最":{"docs":{},"大":{"docs":{},"的":{"docs":{},"缺":{"docs":{},"陷":{"docs":{},"是":{"docs":{},"目":{"docs":{},"前":{"docs":{},"的":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"都":{"docs":{},"是":{"docs":{},"双":{"docs":{},"向":{"docs":{},"的":{"docs":{},"，":{"docs":{},"其":{"docs":{},"严":{"docs":{},"格":{"docs":{},"限":{"docs":{},"制":{"docs":{},"了":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"的":{"docs":{},"选":{"docs":{},"择":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"在":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"g":{"docs":{},"p":{"docs":{},"中":{"docs":{},"，":{"docs":{},"作":{"docs":{},"者":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"从":{"docs":{},"左":{"docs":{},"到":{"docs":{},"右":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"句":{"docs":{},"子":{"docs":{},"中":{"docs":{},"每":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"只":{"docs":{},"能":{"docs":{},"被":{"docs":{},"以":{"docs":{},"前":{"docs":{},"的":{"docs":{},"词":{"docs":{},"所":{"docs":{},"关":{"docs":{},"注":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"对":{"docs":{},"句":{"docs":{},"子":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"是":{"docs":{},"次":{"docs":{},"优":{"docs":{},"的":{"docs":{},"(":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"论":{"docs":{},"文":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"种":{"docs":{},"基":{"docs":{},"于":{"docs":{},"微":{"docs":{},"调":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},":":{"docs":{},"b":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"处":{"docs":{},"理":{"docs":{},"和":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"是":{"docs":{},"密":{"docs":{},"切":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"，":{"docs":{},"其":{"docs":{},"是":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"研":{"docs":{},"究":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{},"内":{"docs":{},"容":{"docs":{},"，":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"研":{"docs":{},"究":{"docs":{},"的":{"docs":{},"两":{"docs":{},"大":{"docs":{},"国":{"docs":{},"际":{"docs":{},"顶":{"docs":{},"会":{"docs":{},"是":{"docs":{},"a":{"docs":{},"a":{"docs":{},"a":{"docs":{},"i":{"docs":{},"和":{"docs":{},"i":{"docs":{},"j":{"docs":{},"c":{"docs":{},"a":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"期":{"docs":{},"刊":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}},"本":{"docs":{},"文":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"（":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}},"作":{"docs":{},"者":{"docs":{},"推":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"套":{"docs":{},"新":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"表":{"docs":{},"达":{"docs":{},"模":{"docs":{},"型":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"，":{"docs":{},"全":{"docs":{},"称":{"docs":{},"为":{"docs":{},"b":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"领":{"docs":{},"域":{"docs":{},"中":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"顶":{"docs":{},"级":{"docs":{},"会":{"docs":{},"议":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"两":{"docs":{},"年":{"docs":{},"一":{"docs":{},"次":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}},"年":{"docs":{},"一":{"docs":{},"次":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0182648401826484}}}}}},"除":{"docs":{},"了":{"docs":{},"上":{"docs":{},"述":{"docs":{},"被":{"docs":{},"c":{"docs":{},"c":{"docs":{},"f":{"docs":{},"收":{"docs":{},"录":{"docs":{},"的":{"docs":{},"会":{"docs":{},"议":{"docs":{},"外":{"docs":{},"，":{"docs":{},"在":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"领":{"docs":{},"域":{"docs":{},"还":{"docs":{},"有":{"docs":{},"其":{"docs":{},"他":{"docs":{},"许":{"docs":{},"多":{"docs":{},"重":{"docs":{},"要":{"docs":{},"会":{"docs":{},"议":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"是":{"docs":{},"s":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},",":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"等":{"docs":{},"。":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"直":{"docs":{},"接":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"外":{"docs":{},"，":{"docs":{},"还":{"docs":{},"有":{"docs":{},"其":{"docs":{},"他":{"docs":{},"许":{"docs":{},"多":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"学":{"docs":{},"术":{"docs":{},"会":{"docs":{},"议":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"信":{"docs":{},"息":{"docs":{},"检":{"docs":{},"索":{"docs":{},"，":{"docs":{},"数":{"docs":{},"据":{"docs":{},"挖":{"docs":{},"掘":{"docs":{},"及":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"领":{"docs":{},"域":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"都":{"docs":{},"是":{"docs":{},"属":{"docs":{},"于":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"应":{"docs":{},"用":{"docs":{},"领":{"docs":{},"域":{"docs":{},"。":{"docs":{},"其":{"docs":{},"中":{"docs":{},"信":{"docs":{},"息":{"docs":{},"检":{"docs":{},"索":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"挖":{"docs":{},"掘":{"docs":{},"与":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"是":{"docs":{},"密":{"docs":{},"切":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"由":{"docs":{},"美":{"docs":{},"国":{"docs":{},"计":{"docs":{},"算":{"docs":{},"机":{"docs":{},"学":{"docs":{},"会":{"docs":{},"（":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"c":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"领":{"docs":{},"域":{"docs":{},"最":{"docs":{},"权":{"docs":{},"威":{"docs":{},"的":{"docs":{},"国":{"docs":{},"际":{"docs":{},"会":{"docs":{},"议":{"docs":{},"，":{"docs":{},"即":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"年":{"docs":{},"会":{"docs":{},"。":{"1":{"9":{"8":{"2":{"docs":{},"年":{"docs":{},"和":{"1":{"9":{"9":{"9":{"docs":{},"年":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"分":{"docs":{},"别":{"docs":{},"成":{"docs":{},"立":{"docs":{},"了":{"docs":{},"欧":{"docs":{},"洲":{"docs":{},"分":{"docs":{},"会":{"docs":{},"（":{"docs":{},"e":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"）":{"docs":{},"和":{"docs":{},"北":{"docs":{},"美":{"docs":{},"分":{"docs":{},"会":{"docs":{},"（":{"docs":{},"n":{"docs":{},"a":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"）":{"docs":{},"两":{"docs":{},"个":{"docs":{},"区":{"docs":{},"域":{"docs":{},"性":{"docs":{},"分":{"docs":{},"会":{"docs":{},"。":{"docs":{},"近":{"docs":{},"年":{"docs":{},"来":{"docs":{},"，":{"docs":{},"亚":{"docs":{},"太":{"docs":{},"地":{"docs":{},"区":{"docs":{},"在":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"研":{"docs":{},"究":{"docs":{},"进":{"docs":{},"步":{"docs":{},"显":{"docs":{},"著":{"docs":{},"，":{"2":{"0":{"1":{"8":{"docs":{},"年":{"7":{"docs":{},"月":{"1":{"5":{"docs":{},"日":{"docs":{},"，":{"docs":{},"第":{"5":{"6":{"docs":{},"届":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"年":{"docs":{},"会":{"docs":{},"在":{"docs":{},"澳":{"docs":{},"大":{"docs":{},"利":{"docs":{},"亚":{"docs":{},"墨":{"docs":{},"尔":{"docs":{},"本":{"docs":{},"举":{"docs":{},"行":{"docs":{},"。":{"docs":{},"开":{"docs":{},"幕":{"docs":{},"仪":{"docs":{},"式":{"docs":{},"上":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"l":{"docs":{},"主":{"docs":{},"席":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{"metting/summit metting.html":{"ref":"metting/summit metting.html","tf":0.0045662100456621}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}},"docs":{}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}},"下":{"docs":{},"载":{"docs":{},"地":{"docs":{},"址":{"docs":{},"：":{"docs":{},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{},"h":{"docs":{},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"p":{"docs":{},"a":{"docs":{},"n":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"s":{"docs":{},"/":{"1":{"docs":{},"n":{"docs":{},"m":{"docs":{},"h":{"3":{"3":{"docs":{},"y":{"docs":{},"k":{"8":{"0":{"docs":{},"s":{"docs":{},"z":{"docs":{},"n":{"docs":{},"k":{"docs":{},"i":{"8":{"docs":{},"v":{"docs":{},"h":{"docs":{},"m":{"docs":{},"e":{"docs":{},"e":{"docs":{},"e":{"docs":{},"a":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}}}}}}}},"docs":{}}}}}}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"时":{"docs":{},"间":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}},"：":{"2":{"0":{"1":{"9":{"docs":{},"年":{"3":{"docs":{},"月":{"2":{"7":{"docs":{},"日":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}},"docs":{}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}},"概":{"docs":{},"述":{"docs":{},"：":{"docs":{},"该":{"docs":{},"p":{"docs":{},"p":{"docs":{},"t":{"docs":{},"是":{"docs":{},"做":{"docs":{},"汇":{"docs":{},"报":{"docs":{},"时":{"docs":{},"候":{"docs":{},"的":{"docs":{},"p":{"docs":{},"p":{"docs":{},"t":{"docs":{},"，":{"docs":{},"讲":{"docs":{},"了":{"docs":{},"知":{"docs":{},"识":{"docs":{},"图":{"docs":{},"谱":{"docs":{},"的":{"docs":{},"基":{"docs":{},"本":{"docs":{},"知":{"docs":{},"识":{"docs":{},"及":{"docs":{},"实":{"docs":{},"体":{"docs":{},"和":{"docs":{},"关":{"docs":{},"系":{"docs":{},"抽":{"docs":{},"取":{"docs":{},"相":{"docs":{},"关":{"docs":{},"论":{"docs":{},"文":{"docs":{},"，":{"docs":{},"有":{"docs":{},"需":{"docs":{},"要":{"docs":{},"可":{"docs":{},"以":{"docs":{},"下":{"docs":{},"载":{"docs":{},"。":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"永":{"docs":{},"久":{"docs":{},"有":{"docs":{},"效":{"docs":{},"）":{"docs":{},"提":{"docs":{},"取":{"docs":{},"码":{"docs":{},"：":{"docs":{},"m":{"docs":{},"d":{"docs":{},"a":{"docs":{},"n":{"docs":{"database/readme.html":{"ref":"database/readme.html","tf":0.14285714285714285}}}}}}}}}}}}}}}},"v":{"1":{"docs":{},".":{"1":{"docs":{},"的":{"docs":{},"问":{"docs":{},"答":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"其":{"docs":{},"f":{"1":{"docs":{},"值":{"docs":{},"达":{"docs":{},"到":{"docs":{},"了":{"9":{"3":{"docs":{},".":{"2":{"docs":{},"（":{"1":{"docs":{},".":{"5":{"docs":{},"%":{"docs":{},"）":{"docs":{},"的":{"docs":{},"绝":{"docs":{},"对":{"docs":{},"提":{"docs":{},"升":{"docs":{},"，":{"docs":{},"比":{"docs":{},"人":{"docs":{},"类":{"docs":{},"的":{"docs":{},"表":{"docs":{},"现":{"docs":{},"都":{"docs":{},"搞":{"docs":{},"了":{"2":{"docs":{},".":{"0":{"docs":{},"的":{"docs":{},"提":{"docs":{},"升":{"docs":{},"。":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{}}}}}},"docs":{}}}}}}}}}},"docs":{}}},"docs":{}},"目":{"docs":{},"录":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}},"前":{"docs":{},"有":{"docs":{},"两":{"docs":{},"种":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"被":{"docs":{},"用":{"docs":{},"于":{"docs":{},"下":{"docs":{},"游":{"docs":{},"处":{"docs":{},"理":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"：":{"docs":{},"基":{"docs":{},"于":{"docs":{},"特":{"docs":{},"征":{"docs":{},"的":{"docs":{},"和":{"docs":{},"基":{"docs":{},"于":{"docs":{},"微":{"docs":{},"调":{"docs":{},"（":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"研":{"docs":{},"究":{"docs":{},"性":{"docs":{},"工":{"docs":{},"作":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456}}}}}}},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"学":{"docs":{},"习":{"docs":{"paper/nlp/readme.html":{"ref":"paper/nlp/readme.html","tf":0.045454545454545456},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{},")":{"docs":{},"，":{"docs":{},"而":{"docs":{},"在":{"docs":{},"针":{"docs":{},"对":{"docs":{},"一":{"docs":{},"些":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"，":{"docs":{},"如":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{},"的":{"docs":{},"问":{"docs":{},"答":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"则":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"有":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"毁":{"docs":{},"灭":{"docs":{},"性":{"docs":{},"的":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"在":{"docs":{},"这":{"docs":{},"些":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"，":{"docs":{},"纳":{"docs":{},"入":{"docs":{},"两":{"docs":{},"个":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"是":{"docs":{},"至":{"docs":{},"关":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"​":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.08823529411764706}}},"作":{"docs":{},"者":{"docs":{},"信":{"docs":{},"息":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"单":{"docs":{},"位":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"关":{"docs":{},"键":{"docs":{},"词":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}},"其":{"docs":{},"他":{"docs":{},"解":{"docs":{},"读":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"内":{"docs":{},"容":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"原":{"docs":{},"文":{"docs":{},"链":{"docs":{},"接":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"实":{"docs":{},"验":{"docs":{},"及":{"docs":{},"结":{"docs":{},"果":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}},"总":{"docs":{},"结":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"我":{"docs":{},"们":{"docs":{},"展":{"docs":{},"示":{"docs":{},"了":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"块":{"docs":{},"可":{"docs":{},"以":{"docs":{},"消":{"docs":{},"除":{"docs":{},"在":{"docs":{},"很":{"docs":{},"多":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"需":{"docs":{},"要":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"严":{"docs":{},"重":{"docs":{},"特":{"docs":{},"征":{"docs":{},"工":{"docs":{},"程":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"摘":{"docs":{},"要":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"是":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"微":{"docs":{},"调":{"docs":{},"方":{"docs":{},"法":{"docs":{},"的":{"docs":{},"语":{"docs":{},"言":{"docs":{},"表":{"docs":{},"示":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"在":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"介":{"docs":{},"绍":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"源":{"docs":{},"码":{"docs":{},"链":{"docs":{},"接":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"相":{"docs":{},"关":{"docs":{},"工":{"docs":{},"作":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}},"简":{"docs":{},"介":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}},"语":{"docs":{},"言":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"已":{"docs":{},"经":{"docs":{},"被":{"docs":{},"证":{"docs":{},"明":{"docs":{},"能":{"docs":{},"有":{"docs":{},"效":{"docs":{},"提":{"docs":{},"升":{"docs":{},"自":{"docs":{},"然":{"docs":{},"语":{"docs":{},"言":{"docs":{},"处":{"docs":{},"理":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"任":{"docs":{},"务":{"docs":{},"包":{"docs":{},"括":{"docs":{},"句":{"docs":{},"子":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"如":{"docs":{},"语":{"docs":{},"言":{"docs":{},"推":{"docs":{},"理":{"docs":{},"及":{"docs":{},"解":{"docs":{},"析":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"任":{"docs":{},"务":{"docs":{},"其":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"从":{"docs":{},"句":{"docs":{},"子":{"docs":{},"级":{"docs":{},"别":{"docs":{},"推":{"docs":{},"断":{"docs":{},"句":{"docs":{},"子":{"docs":{},"间":{"docs":{},"相":{"docs":{},"互":{"docs":{},"关":{"docs":{},"系":{"docs":{},"。":{"docs":{},"此":{"docs":{},"外":{"docs":{},"还":{"docs":{},"包":{"docs":{},"括":{"docs":{},"一":{"docs":{},"些":{"docs":{},"序":{"docs":{},"列":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"如":{"docs":{},"命":{"docs":{},"名":{"docs":{},"实":{"docs":{},"体":{"docs":{},"识":{"docs":{},"别":{"docs":{},"，":{"docs":{},"文":{"docs":{},"本":{"docs":{},"理":{"docs":{},"解":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"任":{"docs":{},"务":{"docs":{},"（":{"docs":{},"s":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"d":{"docs":{},"）":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"任":{"docs":{},"务":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"需":{"docs":{},"要":{"docs":{},"在":{"docs":{},"序":{"docs":{},"列":{"docs":{},"级":{"docs":{},"别":{"docs":{},"产":{"docs":{},"生":{"docs":{},"经":{"docs":{},"过":{"docs":{},"微":{"docs":{},"调":{"docs":{},"后":{"docs":{},"的":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"篇":{"docs":{},"文":{"docs":{},"章":{"docs":{},"的":{"docs":{},"贡":{"docs":{},"献":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}}}}}}}}},"项":{"docs":{},"目":{"docs":{"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"ref":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","tf":0.014705882352941176}}}}},"length":261},"corpusTokens":["11项自然语言处理任务中都取得了目前最好的性能，具体包括将glue的基准值提升到了80.4%(7.6%的绝对提升)，在multnli中准确率有了86.7的提升（5.6%的绝对提升），在squad","11项自然语言处理任务中都取得了目前最好的性能，具体包括将glue的基准值提升到了80.4%(7.6%的绝对提升)，在multnli中准确率达到86.7的（5.6%的绝对提升），在squad","2018年","2019","2019年","aaai,全称是associ","abstract：","abstract：本文作者推出了一套新的语言表达模型bert，全称为bidirect","ac(lth","acl","acl的全称是th","acl（tacl），此外还有一些期刊与自然语言处理相关。如tslp(（acm","acm","acm）主办，包括如下几个会议。","advanc","ai","ai,artifici","aistat","american","approach","ariv","artifici","asia","asian","associ","association)组织","a类","base","bert","bert:","bidirect","b类","ccf","chang,","chapter","cikm,该会议名称缩写和上一个相同，但是其全称为intern","cikmm,其全称是confer","cole","coling(intern","committe","comput","confer","conference，也是有关信息检索及数据挖掘。","conll","conll(confer","c类","data","data&corpu","databas","deep","emnlp","emnlp(confer","emnlp是有acl下面的比较著名的兴趣小组（speci","empir","encod","evaluation,其由欧洲语言资源组织进行elra(european","evaluation,该会议由acl的特殊兴趣小组siglex进行组织，每年都会举办，国内也有很多研究机构及公司参与，如哈工大科大讯飞等,其最新的链接网址如下：http://alt.qcri.org/semeval2019/index.php?id=task","googl","gpt(gener","group","groups,sigs）之一的sigdata(speci","hearst正式宣布成立国际计算语言学学会亚太地区分会（aacl，th","http://coling2018.org","http://emnlp2018.org","http://naacl.org","http://www.conll.org/","https://arxiv.org/abs/1810.04805","https://blog.csdn.net/jilrvrtrc/article/details/83829470","https://blog.csdn.net/lyb3b3b/article/details/83548964","https://www.aclweb.org/port","https://www.cnblogs.com/niuxichuan/p/7602012.html","icml,全称是","ijcai,全称是intern","inform","intellig","intelligence，主要关注人工智能领域的最新研究进展，其中也有大量的人工智能相关的知识。","intelligence，也是关注人工智能领域的另外一个重要学术会议。","interest","intern","introduct","jacobdevlin,m","jair,journ","jmlr,","joint","journal","kenton","keywords:","knowledg","knowledgebas","kristina","languag","learn","learnin)","learning)举办的。其也是每年举办一次，由于naacl是acl在北美的分会，因此当acl在北美举办的时候，naacl就会停办一年。","lee,","level级别的任务中都取得了较好的效果。在很多有特定需要的任务中也取得了较好的效果。","levle和token","linguist","linguistics)","linguistics)组织的。该会议每两年举办一次。","linguistics,其由1965年创办，是由老牌的nlp学术会议组织iccl(th","linguistics,翻译过来是计算机语言协会，自然语言处理与计算语言学领域（以下简称nlp/cl）最权威的国际专业学会，acl成立于1962年，是自然语言处理(nlp)领域影响力最大、最具活力的顶级国际学术组织，每年举办一次。这个学会主办了","linguistics,该会议是acl在北美的分会，也是有acl主办。其是有acl下面的兴趣小组signal(speci","linguistics和transact","linguistics）。此次成立acl亚太分会，将进一步促进亚太地区nlp相关技术和研究的发展。据悉，首届aacl会议预计在2020年举行，此后将每两年举行一次。","lrec","lrec全称是intern","machin","machinery,","management，其关注信息管理","method","mining,由名称可知，该会议关注搜索和数据挖掘。","naacl","naacl(th","naacl的全称是th","natur","nc,neurocompt","neural","nip","nlp","nlp/cl","nlp相关的其他国际会议","north","optimal)，而在针对一些token级别的任务中，如squad的问答问题中，则这种方法有可能是毁灭性的，因此在这些任务中，纳入两个方面的信息是至关重要的。","pacif","paper","pre","process","processing)","processing)),其他相关期刊及投稿链接如下：","processing)举办的。","processing,nlp）领域的一些著名会议及期刊，将按照ccf对会议的分级标准对相关会议进行整理，介绍每个会议的关注主题，召开周期、会议网站及相关的信息，方便后面查找最新的相关论文，从而对该领域进行比较深入的研究。每个会议及期刊都有相关的入口链接，方便进行查看。","processing.","processing）)以及talip((acm","represent","research","resourc","retrieval,其主要关注信息检索。","search","semant","semev","semeval,其全称是intern","sigir,其全称是speci","speech","statist","system","tool","toutanova","train","transact","transform","transform)引入了最小任务的参数，在下游任务中，其通过简单的微调的方式来调整模型的参数。在以前的工作中，所有的预训练方法都是通过使用同样的目标函数并通过双向语言模型来学习更好的通用语言表示。","transformers(基于双向翻译编码的表示模型)。bert通过提出了两个新的预训练目标来解决以前的提到的单向限制问题：基于“masked”的语言模型（mlm），这种方法在1953年就曾经被提出。这种语言模型通过随机将输入句子中的token进行隐藏，然后预训练的目标就是基于上下文来预测出被覆盖掉的单词。不同于传统的从左到右的预训练语言模型，mlm训练目标使得我们能够充分利用左边和右边信息来训练一个更深的双向翻译模型。除了利用masked语言模型外，我们还在模型中引入了预测下一个句子的训练目标来同时训练句子对级别的表示模型。","transformers。与近年来提出的语言模型不一样的地方在于，bert不再仅仅是只关注一个词前文或后文的信息，而是整个模型的所有层都去关注其整个上下文的语境信息。实验结果证明，使用预训练过的bert模型，仅仅在后面再包一层输出层，并对其进行微调训练，就可以将其应用到其他多种任务中，例如问答、语言推断等，并且在这些后端任务中并不需要根据特定的任务需要对模型结构进行修改。bert是一种概念上简单，但在实际中却有强大的性能的模型。bert在","transformers。与近年来提出的语言模型不一样的地方在于，bert不再仅仅是只关注一个词前文或后文的信息，而是整个模型的所有层都去关注其整个上下文的语境信息。实验结果证明，使用预训练过的bert模型，仅仅在后面再包一层输出层，并对其进行微调训练，就可以将其应用到其他多种任务中，例如问答、语言推断等，并且在这些后端任务中并不需要根据特定的任务需要对模型结构进行修改。bert是一种概念上简单，但根据经验推断其具有强大的性能。bert在","tuning）的方法。在基于特征的方法中，elmo(2018)是一种基于特征任务的模型，其包含一个预训练模型以及一些其他的特征。在微调模型中，openai","uai","uncertainti","understand","v1.1的问答任务中其f1值达到了93.2（1.5%）的绝对提升，比人类的表现都搞了2.0的提升。","web","wei","wide","workshop","world","wsdm,该会议全称为web","​","下载地址：链接：https://pan.baidu.com/s/1nmh33yk80sznki8vhmeeea","人工智能领域与自然语言处理相关的会议","以下是根据ccf2015年的对自然语言处理领域的会议的分级标准来进行罗列和整理","会议名称","会议网站","作者信息","作者单位","全称","全称是confer","全称是intern","关键词","其他解读","内容","出版社","分享者：刘露平","分析解读最新的自然语言处理方面的论文，供大家一起进行交流和学习。","分类等级","原文链接","参考文献","召开周期","国际会议","在11项自然语言处理任务中都取得了sota的结果。表明双向语言模型在文本处理中的重要性。","在国际上acl，coling，enmlp和naacl是默认的四大自然语言处理顶级学术会议，其中acl，emnlp和naacl都是由acl及相应的子组织举办的。","在自然语言处理中，一般来将，大家更关注学术会议，其主要原因是发表周期短，通过会议也可以进行深入的交流。但自然语言处理领域也有自己的学术期刊，其旗舰期刊有两个，分别是comput","在自然语言处理中，机器学习也是其主流的方法，在机器学习领域相关的学术会议包括icml,nips,uai及aistats,下面将简单介绍。","在这篇文章中我们证明了双向预训练模型的重要性。不同于传统的双向预测模型，bert使用了一种基于masked的语言模型来训练一种更深的语言模型。此外区别于传统的浅层双向语言模型，bert是一种使用深层次的双向语言模型。","在这篇文章中，我们任务目前的技术严重限制了预训练在语言表达方面的能力，特别是针对微调的方法。最大的缺陷是目前的预训练模型都是双向的，其严格限制了模型在进行预训练时的选择能力。例如在openaigp中，作者使用了从左到右的模型，使得句子中每个token只能被以前的词所关注。这种方式对句子级别的任务是次优的(sub","在这篇论文中，我们提出了一种基于微调的方法bert:bidirect","处理和人工智能是密切相关的，其是人工智能研究的重要内容，人工智能研究的两大国际顶会是aaai和ijcai","实验及结果","将相关的知识进行整理后分享，方便后面的人学习","将自然语言处理方面的工具进行整理汇总","工具整理","总结","我们展示了预训练模块可以消除在很多任务中需要依赖严重特征工程的任务。bert","摘要","收集整理相关成员上传的资料及相应的数据集，方便有需要的同学进行下载。","收集整理自然语言处理领域的会议及期刊，方便大家进行相关的查阅。","数据集","时间","时间：2019年3月27日","是第一个基于微调方法的语言表示模型，并且在sentenc","期刊","本文介绍自然语言处理（natur","本文作者推出了一套新的语言表达模型bert，全称为bidirect","机器学习领域中与自然语言处理相关的顶级会议","概述：该ppt是做汇报时候的ppt，讲了知识图谱的基本知识及实体和关系抽取相关论文，有需要可以下载。","模型介绍","每两年一次","每年一次","源码链接","目前有两种预训练的方法被用于下游处理任务中：基于特征的和基于微调（fine","目录","相关工作","知识分享","知识图谱概述ppt","研究性工作","简介","自然语言","自然语言处理会议及期刊","论文解读","该博客主要收集整理与自然语言处理相关工具，论文以及代码等资源信息，对目前自然语言处理最前沿的技术、论文及相关相关代码进行整理后进行分享，主要关注点包括自然语言处理基础方法，知识图谱构建，智能问答等几个方面的知识。通过不断地积累让大家在这条路上越走越远。","该部分主要是分享目前自然语言及知识图谱处理方法的基础知识，目前包含如下三个方面：自然语言处理基础技术，知识图谱构建，智能问答,论文整理将按照年份和板块来进行整理。","该页面收集整理日常工作中相关的数据集和资料，大家可以通过将相关资料放到网盘或者其他github仓库中，然后这里放上相应的链接。","语言预训练模型已经被证明能有效提升自然语言处理任务的性能。这些任务包括句子级别的任务如语言推理及解析，这些任务其目的是从句子级别推断句子间相互关系。此外还包括一些序列级别的任务，如命名实体识别，文本理解挑战任务（squad），这些任务模型中需要在序列级别产生经过微调后的更好的结果。","这篇文章的贡献如下：","除了上述被ccf收录的会议外，在自然语言处理领域还有其他许多重要会议，分别是semeval,lrec等。","除了直接与自然语言处理相关外，还有其他许多与自然语言处理相关的学术会议，包括信息检索，数据挖掘及人工智能领域，这些都是属于自然语言处理的应用领域。其中信息检索和数据挖掘与自然语言处理是密切相关的，主要由美国计算机学会（associ","项目","预训练，迁移学习","领域最权威的国际会议，即acl年会。1982年和1999年，acl分别成立了欧洲分会（eacl）和北美分会（naacl）两个区域性分会。近年来，亚太地区在自然语言处理方面的研究进步显著，2018年7月15日，第56届acl年会在澳大利亚墨尔本举行。开幕仪式上，acl主席marti","（永久有效）提取码：mdan"],"pipeline":["stopWordFilter","stemmer"]},"store":{"./":{"url":"./","title":"Introduction","keywords":"","body":"该博客主要收集整理与自然语言处理相关工具，论文以及代码等资源信息，对目前自然语言处理最前沿的技术、论文及相关相关代码进行整理后进行分享，主要关注点包括自然语言处理基础方法，知识图谱构建，智能问答等几个方面的知识。通过不断地积累让大家在这条路上越走越远。\n自然语言处理会议及期刊\n收集整理自然语言处理领域的会议及期刊，方便大家进行相关的查阅。\n工具整理\n将自然语言处理方面的工具进行整理汇总\n数据集\n收集整理相关成员上传的资料及相应的数据集，方便有需要的同学进行下载。\n论文解读\n分析解读最新的自然语言处理方面的论文，供大家一起进行交流和学习。\n知识分享\n将相关的知识进行整理后分享，方便后面的人学习\n"},"metting/summit metting.html":{"url":"metting/summit metting.html","title":"Conferences and journals","keywords":"","body":"本文介绍自然语言处理（Natural Language Processing,NLP）领域的一些著名会议及期刊，将按照CCF对会议的分级标准对相关会议进行整理，介绍每个会议的关注主题，召开周期、会议网站及相关的信息，方便后面查找最新的相关论文，从而对该领域进行比较深入的研究。每个会议及期刊都有相关的入口链接，方便进行查看。\n国际会议\n以下是根据CCF2015年的对自然语言处理领域的会议的分级标准来进行罗列和整理\n\n   \n      分类等级\n      会议名称\n      召开周期\n      出版社\n      会议网站\n   \n   \n      CCF A类\n      AC(LThe Association for Computational Linguistics)\n      每年一次\n      ACL\n      https://www.aclweb.org/portal\n   \n   \n      \n   \n   \n      CCF B类\n      COLING(International Conference on Computational Linguistics)\n      每年一次\n      ACL\n      http://coling2018.org\n   \n   \n      \n   \n   \n      \n      EMNLP(Conference on Empirical Methods in Natural Language Processing)\n      每年一次\n      ACM\n      http://emnlp2018.org\n   \n   \n      \n   \n   \n      CCF C类\n      NAACL(The North American Chapter of the Association for Computational Linguistics)\n      每年一次\n      NAACL\n      http://naacl.org\n   \n   \n      \n   \n   \n      \n      CoNLL(Conference on Computational Natural Language Learnin)\n      每两年一次\n      CoNLL\n      http://www.conll.org/\n   \n   \n      \n   \n\n\n\n在国际上ACL，COLING，ENMLP和NAACL是默认的四大自然语言处理顶级学术会议，其中ACL，EMNLP和NAACL都是由ACL及相应的子组织举办的。\nACL\nACL的全称是The Association for Computational Linguistics,翻译过来是计算机语言协会，自然语言处理与计算语言学领域（以下简称NLP/CL）最权威的国际专业学会，ACL成立于1962年，是自然语言处理(NLP)领域影响力最大、最具活力的顶级国际学术组织，每年举办一次。这个学会主办了 NLP/CL 领域最权威的国际会议，即ACL年会。1982年和1999年，ACL分别成立了欧洲分会（EACL）和北美分会（NAACL）两个区域性分会。近年来，亚太地区在自然语言处理方面的研究进步显著，2018年7月15日，第56届ACL年会在澳大利亚墨尔本举行。开幕仪式上，ACL主席Marti Hearst正式宣布成立国际计算语言学学会亚太地区分会（AACL，The Asia-Pacific Chapter of Association for Computational Linguistics）。此次成立ACL亚太分会，将进一步促进亚太地区NLP相关技术和研究的发展。据悉，首届AACL会议预计在2020年举行，此后将每两年举行一次。\nCOLING\nCOLING 全称是International Conference on Computational Linguistics,其由1965年创办，是由老牌的NLP学术会议组织ICCL(The International Committee on Computational Linguistics)组织的。该会议每两年举办一次。\nEMNLP\nEMNLP 全称是Conference on Empirical Methods in Natural Language Processing. EMNLP是有ACL下面的比较著名的兴趣小组（Special Interest Groups,SIGS）之一的SIGDATA(Special Interest Group on Linguistic Data&Corpus-based Approaches to Natural Language Processing)举办的。\nNAACL\nNAACL的全称是The North American Chapter of the Association for Computational Linguistics,该会议是ACL在北美的分会，也是有ACL主办。其是有ACL下面的兴趣小组SIGNAL(special Interest Group on Natural Language Learning)举办的。其也是每年举办一次，由于NAACL是ACL在北美的分会，因此当ACL在北美举办的时候，NAACL就会停办一年。\n除了上述被CCF收录的会议外，在自然语言处理领域还有其他许多重要会议，分别是SemEval,LREC等。\nSemEval\nSemEval,其全称是International Workshop on Semantic Evaluation,该会议由ACL的特殊兴趣小组SIGLEX进行组织，每年都会举办，国内也有很多研究机构及公司参与，如哈工大科大讯飞等,其最新的链接网址如下：http://alt.qcri.org/semeval2019/index.php?id=tasks\nLREC\nLREC全称是International Conference on Language Resource and Evaluation,其由欧洲语言资源组织进行ELRA(European Language Resources Association)组织\nNLP相关的其他国际会议\n除了直接与自然语言处理相关外，还有其他许多与自然语言处理相关的学术会议，包括信息检索，数据挖掘及人工智能领域，这些都是属于自然语言处理的应用领域。其中信息检索和数据挖掘与自然语言处理是密切相关的，主要由美国计算机学会（Association for Computing Machinery, ACM）主办，包括如下几个会议。\nSIGIR,其全称是Special Interest Group on Informational Retrieval,其主要关注信息检索。\nCIKMM,其全称是Conference on Information and Knowledge Management，其关注信息管理\nCIKM,该会议名称缩写和上一个相同，但是其全称为International World Wide Web Conference，也是有关信息检索及数据挖掘。\nWSDM,该会议全称为Web Search and Data Mining,由名称可知，该会议关注搜索和数据挖掘。\n人工智能领域与自然语言处理相关的会议\n自然语言 处理和人工智能是密切相关的，其是人工智能研究的重要内容，人工智能研究的两大国际顶会是AAAI和IJCAI\nAAAI,全称是Association for the Advancement of Artificial Intelligence，主要关注人工智能领域的最新研究进展，其中也有大量的人工智能相关的知识。\nIJCAI,全称是International Joint Conferences on Artificial Intelligence，也是关注人工智能领域的另外一个重要学术会议。\n机器学习领域中与自然语言处理相关的顶级会议\n在自然语言处理中，机器学习也是其主流的方法，在机器学习领域相关的学术会议包括ICML,NIPS,UAI及AISTATS,下面将简单介绍。\nICML,全称是 International Conference on Machine Learning\nNIPS 全称 Conference on Neural Information Processing Systems\nUAI 全称 Conference on Uncertainty in Artificial Intelligence\nAISTATS 全称 International Conference on Artificial Intelligence and Statistics\n期刊\n在自然语言处理中，一般来将，大家更关注学术会议，其主要原因是发表周期短，通过会议也可以进行深入的交流。但自然语言处理领域也有自己的学术期刊，其旗舰期刊有两个，分别是Computational Linguistics和Transactions of ACL（TACL），此外还有一些期刊与自然语言处理相关。如TSLP(（ACM Transactions on Speech and Language Processing）)以及TALIP((ACM Transactions on Asian Language Information Processing)),其他相关期刊及投稿链接如下：\nAI,Artificial Intelligence\nJAIR,Journal of AI Research\nJMLR, Journal of Machine Learning Research\nNC,Neurocompting\n参考文献\n\nhttps://blog.csdn.net/lyb3b3b/article/details/83548964\nhttps://www.cnblogs.com/niuxichuan/p/7602012.html\n\n"},"tools/readme.html":{"url":"tools/readme.html","title":"tools","keywords":"","body":""},"database/readme.html":{"url":"database/readme.html","title":"database","keywords":"","body":"该页面收集整理日常工作中相关的数据集和资料，大家可以通过将相关资料放到网盘或者其他github仓库中，然后这里放上相应的链接。\n\n知识图谱概述PPT\n\n时间：2019年3月27日\n分享者：刘露平\n下载地址：链接：https://pan.baidu.com/s/1nmH33YK80SZNKI8VHmEeEA （永久有效）提取码：mdan \n概述：该PPT是做汇报时候的PPT，讲了知识图谱的基本知识及实体和关系抽取相关论文，有需要可以下载。\n\n\n\n"},"paper/readme.html":{"url":"paper/readme.html","title":"paper","keywords":"","body":"该部分主要是分享目前自然语言及知识图谱处理方法的基础知识，目前包含如下三个方面：自然语言处理基础技术，知识图谱构建，智能问答,论文整理将按照年份和板块来进行整理。\n\n2019\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding--ariv\n\n"},"paper/nlp/readme.html":{"url":"paper/nlp/readme.html","title":"NLP","keywords":"","body":"目录\n\n2019年\n\n2018年\n研究性工作\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding--ariv\nAbstract： 本文作者推出了一套新的语言表达模型BERT，全称为Bidirectional Encoder Representations from Transformers。与近年来提出的语言模型不一样的地方在于，BERT不再仅仅是只关注一个词前文或后文的信息，而是整个模型的所有层都去关注其整个上下文的语境信息。实验结果证明，使用预训练过的BERT模型，仅仅在后面再包一层输出层，并对其进行微调训练，就可以将其应用到其他多种任务中，例如问答、语言推断等，并且在这些后端任务中并不需要根据特定的任务需要对模型结构进行修改。Bert是一种概念上简单，但根据经验推断其具有强大的性能。BERT在 11项自然语言处理任务中都取得了目前最好的性能，具体包括将GLUE的基准值提升到了80.4%(7.6%的绝对提升)，在MultNLI中准确率有了86.7的提升（5.6%的绝对提升），在SQuAD v1.1的问答任务中其F1值达到了93.2（1.5%）的绝对提升，比人类的表现都搞了2.0的提升。       \nkeywords:  预训练，迁移学习\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html":{"url":"paper/nlp/papers/BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.html","title":"BERT Pre-training of Deep Bidirectional Transformers for Language Understanding","keywords":"","body":"\nBERT Pre-training of Deep Bidirectional Transformers for Language Understanding\n\n\n\n\n项目\n内容\n\n\n\n\n时间\n2018年\n\n\n作者单位\nGoogle\n\n\n作者信息\nJacobDevlin,Ming-Wei Chang, Kenton Lee, Kristina Toutanova\n\n\n源码链接\n\n\n\n原文链接\nhttps://arxiv.org/abs/1810.04805\n\n\n其他解读\nhttps://blog.csdn.net/jilrvrtrc/article/details/83829470\n\n\n关键词\n预训练，迁移学习\n\n\n\n摘要\nAbstract：本文作者推出了一套新的语言表达模型BERT，全称为Bidirectional Encoder Representations from Transformers。与近年来提出的语言模型不一样的地方在于，BERT不再仅仅是只关注一个词前文或后文的信息，而是整个模型的所有层都去关注其整个上下文的语境信息。实验结果证明，使用预训练过的BERT模型，仅仅在后面再包一层输出层，并对其进行微调训练，就可以将其应用到其他多种任务中，例如问答、语言推断等，并且在这些后端任务中并不需要根据特定的任务需要对模型结构进行修改。Bert是一种概念上简单，但在实际中却有强大的性能的模型。BERT在 11项自然语言处理任务中都取得了目前最好的性能，具体包括将GLUE的基准值提升到了80.4%(7.6%的绝对提升)，在MultNLI中准确率达到86.7的（5.6%的绝对提升），在SQuAD v1.1的问答任务中其F1值达到了93.2（1.5%）的绝对提升，比人类的表现都搞了2.0的提升。   \n简介\n​    语言预训练模型已经被证明能有效提升自然语言处理任务的性能。这些任务包括句子级别的任务如语言推理及解析，这些任务其目的是从句子级别推断句子间相互关系。此外还包括一些序列级别的任务，如命名实体识别，文本理解挑战任务（SQuAD），这些任务模型中需要在序列级别产生经过微调后的更好的结果。\n​    目前有两种预训练的方法被用于下游处理任务中：基于特征的和基于微调（fine-tuning）的方法。在基于特征的方法中，ELMO(2018)是一种基于特征任务的模型，其包含一个预训练模型以及一些其他的特征。在微调模型中，OpenAI GPT(Generative Pre-trained Transform)引入了最小任务的参数，在下游任务中，其通过简单的微调的方式来调整模型的参数。在以前的工作中，所有的预训练方法都是通过使用同样的目标函数并通过双向语言模型来学习更好的通用语言表示。\n​    在这篇文章中，我们任务目前的技术严重限制了预训练在语言表达方面的能力，特别是针对微调的方法。最大的缺陷是目前的预训练模型都是双向的，其严格限制了模型在进行预训练时的选择能力。例如在OpenAIGP中，作者使用了从左到右的模型，使得句子中每个token只能被以前的词所关注。这种方式对句子级别的任务是次优的(sub-optimal)，而在针对一些token级别的任务中，如SQuAD的问答问题中，则这种方法有可能是毁灭性的，因此在这些任务中，纳入两个方面的信息是至关重要的。\n​    在这篇论文中，我们提出了一种基于微调的方法BERT:Bidirectional Encoder Representations from Transformers(基于双向翻译编码的表示模型)。BERT通过提出了两个新的预训练目标来解决以前的提到的单向限制问题：基于“masked”的语言模型（MLM），这种方法在1953年就曾经被提出。这种语言模型通过随机将输入句子中的token进行隐藏，然后预训练的目标就是基于上下文来预测出被覆盖掉的单词。不同于传统的从左到右的预训练语言模型，MLM训练目标使得我们能够充分利用左边和右边信息来训练一个更深的双向翻译模型。除了利用masked语言模型外，我们还在模型中引入了预测下一个句子的训练目标来同时训练句子对级别的表示模型。\n​    这篇文章的贡献如下：\n\n在这篇文章中我们证明了双向预训练模型的重要性。不同于传统的双向预测模型，BERT使用了一种基于masked的语言模型来训练一种更深的语言模型。此外区别于传统的浅层双向语言模型，BERT是一种使用深层次的双向语言模型。\n我们展示了预训练模块可以消除在很多任务中需要依赖严重特征工程的任务。BERT 是第一个基于微调方法的语言表示模型，并且在sentence-levle和token-level级别的任务中都取得了较好的效果。在很多有特定需要的任务中也取得了较好的效果。\nBERT 在11项自然语言处理任务中都取得了SOTA的结果。表明双向语言模型在文本处理中的重要性。\n\n\n相关工作\n模型介绍\n实验及结果\n总结\n​      \n"},"paper/KnowledgeBase/readme.html":{"url":"paper/KnowledgeBase/readme.html","title":"KnowledgeBase","keywords":"","body":""}}}